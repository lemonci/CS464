Authors:           Wing Shu Leung,       Monica Li,             William Nugent
Emails:            wleung19@ubishops.ca, mli@cs.ubishops.ca,    WNUGENT20@UBishops.ca
Student ID number: 002272638,            002285699              002287187
===================================================================================================
Assignment 4 - 
Build a Concurrent File Server with Preallocated Threads, Basic Signals and Synchronized Peers
--------------------------------------------------------------------------------------------------
GENERAL OVERVIEW 

The code is based from the solution to Assignment 3 (CS 464/564, Fall 2021) of Stefan Bruda.
Please read the section 'SPECIFICATIONS FROM ASSIGNMENT 3' to comprehend the complete code.

No new file are being added in the scope of this assignment. We mainly focus on changing the 
functionalities of misc.cc, shfd.h (for global variables) and fserv.cc. New functions are added in
misc.cc. Only file_client() in fserv.cc was modified for concurrency and replication.
--------------------------------------------------------------------------------------------------
SPECIFICATIONS OF ASSIGNMENT 4


PART 1 - Restict shell server commands
In shell_server() we have turned it into an iterative server (by removing thread creation)
instead of a multithreaded server. That way it can serve only one client at a time.

We have switched the master socket so it can only listen to local machine only using the prexisting
function controlsocket() (with INADDR_LOOPBACK).


PART 2 - Concurrency management
Using the distributed approach, the preallocated threads (incr_treads) will monitor each other
whether if new threads should be created (until it reaches max_threads) or it should killed itself 
to release ressources from having too many idle threads in the server. 

We keep the maximum (max_threads), current total(curr_threads), the increment of each thread creation
(incr_threads) and active threads (act_threads) as global variables. 
Flags such as falive and talive were used as global variables to keep a check on the threads if they 
need to be alive or if file server is closed by signal quit or hangup. 

From assignment 3, we modify the functionality of file_server such that it will be the threads that 
will handle the clients (from file_client) instead of master thread file_server. File server exists
to keep the preallocated threads alive. We create preallocated threads using set_threads() 
and return a value determining whether or not any more threads may be created.

The general concept to create new preallocated threads is as follow: if all current threads are active,
set_threads() should activate. If it reaches to the maximum of threads, set_threads() stop creating 
new threads. We use poll() to monitor the number of idle threads at the master socket. If it is deemed 
to be too much (after 1 minute), we will call handle_thread(). The first idle thread that reach 
this function will delete themselve until it has reached the appropriate level of preallocated threads. 
We find whether these connections are inactive by repeatedly polling them periodically and
reacting accordingly to it.
\
set_threads() and handle_threads() are in misc.cc


PART 3 - SIGNAL HANDLER
Signal handler makes sure that when the signal SIGQUIT is received then it triggers deal_SIGQUIT()
and makes sure to shutdown all servers and deleting/closing all threads (including the ones that are 
acitvely serving clients).

To do so, instead of being blocked on accept(), we blocked on poll() to check the flag talive is still
active. If so, normal procedures of file_client shall resume, else it shall exit from the loop by
shutting down and closing the socket, resume back at being an idle thread where it will be handle by 
handle_threads() to kill itself.

Similarly, once the signal SIGHUP is received, then it triggers deal_SIGHUP(), 
which ends all threads, the server and then reboots the system; reassigning global variables, 
reassigning threads, and setting up the file server. The flag talive will be putted back up. The 
clients who were before the HANGUP will be politely being shutdown and close. They only need to
call back the master socket for the reconnection to be established.


PART 4 - REPLICATION

FOPEN/FSEEK/FWRITE/FCLOSE will be dexectute the commands locally and then sent the same command from client
to the peers via the peer socket.

The server will exectute FREAD locally and store the FREAD result in an 2D array with count 1. Then the server will 
send the command to the peers using peer socket and receive their responses. Then the server will check the responses
to the existing FREAD results in the array. If a response never appears in the array, it will be stored in a new row
with count 1; if a response has already appeared in the array, the count of such a response will be incremented. Finally,
the response with largest count will be sent to client. If there is no max/more than one max count, sync fail will be
sent to client.

PART 5 - COMMANDLINE
Nothing much has changed except that we now we accepted the following command line:

  serv [-d] [-D] [-v all|file|comm] [-f port] [-s port] [-p port] [-t incr_thread] [-T max_threads] [host:port]

where

  -f  overrides the default file server port
  -s  overrides the default shell server port
  -p  overrides the default peer server port
  -t  overrides the default increment of preallocated thread
  -T  overrides the default maximum thread
  -d  does not detach (debugging mode)
  -D  delays read and write operations (see report for rationale)
  -v  comm: prints out (to stdout) messages related to communication
            events
      file: prints out (to stdout) messages related to file access
      all:  `-v comm' and `-v file' together

   The remaining arguments are the host information (ip or host name) followed by a ":" 
   and its port number. 

***Note that our server do not use a peer port (we assign a new one each time we communicate with
our peers). Hence the argument of pport will connect and then exit (it will be notify from the server
side).

--------------------------------------------------------------------------------------------------

SPECIFICATIONS FROM ASSIGNMENT 3 (CODE'S AUTHOR IS PROFESSOR STEFAN BRUDA). 

The server is implemented in the files shfd.h (header for everything),
fserv.cc (code for the file server), shserv.cc (code for the shell
server), and misc.cc (common code and main functions) as a no-frills,
multithreaded server.  It also detaches by default from the terminal
and redirects output to the file "shfd.log" in the current working
directory.

1. User guide: 

The following command line is accepted:

  bbserv [-d] [-D] [-v all|file|comm] [-f port] [-s port]

where

  -f  overrides the default file server port
  -s  overrides the default shell server port
  -d  does not detach (debugging mode)
  -D  delays read and write operations (see report for rationale)
  -v  comm: prints out (to stdout) messages related to communication
            events
      file: prints out (to stdout) messages related to file access
      all:  `-v comm' and `-v file' together

The options can be given in any order and any combination (I used the
getopt library).

The server works with any kind of client, including telnet.  The
problem with the telnet is that it sends \r\n-terminated requests
instead of the Unix-like \n-terminated requests.  For compatibility
with clients we designed throughout the course on the other hand, a
server should also accept \n-terminated requests.  So this server
accepts _both_ formats (specifically, it eats up the terminating \r if
present), and its responses are all \r\n-terminated.


2. Supporting files:

 o  Module tcp-utils, unchanged except for adding code that makes the
    socket reusable.

 o  Module tokenize, unchanged.

 o  The makefile, whose target `all' makes the server (the client is
    _not_ made by default).

 o  File client.cc, mostly the same as triv_client, except that it blocks
    until it receives one full line, and then has a very short timeout
    for anything else.  In fact, it is not supposed to receive more
    than one line except when the server returns the output of a shell
    command.
 
    So this client does not make much sense, since one can use telnet
    to interact with the server (and I have been using telnet while
    testing the server too).  However, this client features a prompt,
    which is not the case with telnet and which could help in
    debugging by differentiating between an empty response and a
    non-response, so I thought I will just include it.


3. Implementation details

There is nothing spectacular in there really, except perhaps the
access control and the handling of information for opened files.
Other than this, the thing is a simple, multithreaded server similar
to the one you have already seen.

Notice that the server detaches itself from the controlling terminal,
closes descriptors, redirects the output to a file, and in general
does the things a well-behaved server is supposed to do.  It does not
change directory though, since it is more convenient for demonstration
purposes to make it run in the directory from which it was launched.

The file server commands are case insensitive, everything else is case
sensitive.

Most data structures are allocated dynamically.  That there are no
memory leaks has been insured by code inspection and by the use of
valgrind.


3.1. The shell server

The shell server is really simple, there is nothing much to be said
about it.  Before doing execv* to execute the requested commands the
descriptors 1 and 2 of the child process are all re-opened to a
temporary file which is listed through the communication socket by
subsequent CPRINT commands.  There is one such a temporary file for
every client (so that one client does not get the output of a command
issued by the other client).

The search path is inherited from the process that launches the
server.  This is a bad security choice but once more convenient for
testing purposes.


3.2. Access control

Access control to files is accomplished by a mutexed structure which
contains a condition variable for writing and a counter for the
reading processes that happen concurrently.

A writing process acquires the mutex and does not release it until the
writing is completed.  However, such a process has to wait for all the
current reading processes to complete before doing anything.
Meantime, the mutex should be temporarily released (otherwise reading
processes will not be able to signal completion).  So, the writing
process also waits on a condition variable that is signaled as soon
as the number of concurrent reading processes reaches the value 0, as
follows (where mutex is the mutex, cond is the condition, and rd is the
number of concurrent reading processes, the latter two protected by
mutex):

      pthread_mutex_lock(&mutex);
      while (rd != 0) {
        pthread_cond_wait(&cond, &mutex);
      }

      // Do the effective writing

      pthread_cond_broadcast(&cond); // so that other waiting 
                                     // processes are notified
      pthread_mutex_unlock(&mutex);

The read process also acquires the mutex in order to increment (and
later decrement) the number rd of reading processes, but after
incrementing this counter the mutex is released.  This allows for
concurrent reads, while writing processes will be prevented to go
ahead by the non-zero value of rd.  A reading process is thus
summarized by the following pseudo-code (with the same notation as
above):

      pthread_mutex_lock(&mutex);
      rd++;
      pthread_mutex_unlock(&mutex);
    
      // Do the effective reading (outside any critical region!)
    
      pthread_mutex_lock(&mutex);
      rd--;
      if (rd == 0)
        pthread_cond_broadcast(&cond);  // so that waiting writing
                                        // processes are notified
      pthread_mutex_unlock(&mutex);

All of this could have been accomplished without using the condition
variable, but this is the most efficient solution.

Note that seeking has an potential impact similar to writing, so we
use for seeking the same access algorithm as for writing.


3.3. Keeping track of opened files

One access control structure (containing a mutex, a condition
variable, and the number of clients--the "owners"--that have requested
the file to be opened) exists for every opened file.  The opened files
are recorded in an array of pointers to structures.  When closing a
file, the owner field of the corresponding structure is decremented.
If this field becomes zero, then the file is effectively closed and
the structure is deallocated; otherwise the file remains open.  Once a
client closes its connection, we close (in the sense above) all the
files opened by that client in order to make sure that we do not waste
resources.

A first idea for avoiding opening the same file twice is to store the
name of each file in the respective access control structure and
compare the name of any new file with the names of the files already
opened.  We further store names by absolute path to avoid trivial
variants of a name to be considered different.  This works reasonably
well in most circumstances, but fails for hard and soft links and also
for shell shortcuts such as the ~ shortcut.  You can still see this
approach in my code, but commented out since we can easily implement a
better approach.

The best solution for comparing files is to note that a file name is a
pointer to that file's inode.  The inode in turn is unique to each
physical file in the file system, no matter under which name that
inode is accessed.  Therefore we store the inode of each opened file
in the access contrl structure.  Then we compare the inode of any new
file to the ones already stored, thus identifying whether the new file
is indeed new or it has been opened already.  Needless to say, inode
comparison works over everything, including hard links, symbolic
links, and shell shortcuts.

Obtaining the inode of a file is easy using the fstat() system call:
Let fd contain the descriptor of a file.  Then the following piece of
code will obtain the inode of that file:

struct stat file_info;
int ret = fstat(fd, &file_info);

Assuming that ret == 0, file_info.st_ino contains at this point the
inode of fd.  Piece of cake.


4. Tests

Normal operation has been tested interactively with multiple clients
connected simultaneously.  No surprises here, all the commands work as
advertised except for the bugs below.

The shell server is too simple to linger too much on.  Various
existing and non-existing commands have been issued, plus interleaving
CPRINT commands.  Everything just works.

In order to test the correct access control to the opened files, I
have used the -v and -D switches.  I used three clients connected
simultaneously to the same server and I followed the following
scenarios:

o  The three clients issue read requests quasi-simultaneously: There
   is a ~20 seconds wait and then all the three responses appear.
   Obviously, reading is concurrent.

o  The three clients issue write requests quasi-simultaneously: The
   responses are given ~5 seconds apart, which shows that write is
   exclusive.

o  A client issues a write request, two other follow with read
   requests quasi-simultaneously.  There is the ~5 seconds delay for
   the response to the write request /and/ a supplementary delay of
   ~20 seconds for the responses to the read requests.  Thus, no read
   can start if a write is already in progress.

o  Similarly to the above scenario, but the write request is the last.
   The delays are reversed (but the total delay remains ~25 seconds),
   which shows that no write starts until all the reads complete.

This provides conclusive evidence that the access control, as well as
the application protocol, work as required.

The following I/O error conditions have also been tested:

o  Errors in the command line arguments are handled correctly (server
   refuses to start and displays a usage message).

o  Socket binding: appropriate error messages have been signaled for
   ports already in use, ports with forbidden access, etc.  The server
   refuses to start in all of this cases.

o  Various scenarios with files lacking sufficient permissions have
   been tested and have been handled correctly.

All the tests are reproducible, so no output is provided.


4.1.  Known bugs

o  An exec error or an error in manipulating the output file for
   external commands are signalled by a 0xFF status code sent back to
   the parent process.  If an application that is actually executed
   exits with this code, then the server will send back to the client
   no message (it should have sent a FAIL message).

o  If a file contains null bytes the result of an FREAD command may be
   incorrect.  Note that current clients are unable to send null
   bytes.

o  The logging is not really portable, in that the IP addresses of the
   clients are assumed to be IPv4 addresses.

o  All failed system calls should have been logged but not all of them
   are in the current version.

o  The shell server could use more debugging code (and a debugging
   option of its own too).  It does seem too simple to pose problems,
   but one never knows.

o  The code in general is kind of kludgy being written in a hurry.
   There is no encapsulation and besides memory management the code is
   largely C.  I actually chose to implement the thing in C++
   precisely because of the memory management system (which is in my
   opinion much saner than C's).
